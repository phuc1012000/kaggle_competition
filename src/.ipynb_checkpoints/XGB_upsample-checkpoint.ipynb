{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T02:58:49.170394Z",
     "start_time": "2019-12-15T02:58:48.965784Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from numba import jit\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phuc import data_process, file\n",
    "from phuc import visualization as vs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file data_path.pkl\n",
      "Directory  /home/phuc/Desktop/Work/Data Sience/kaggle_competition/SafeDirverPrediction  already exists\n",
      "Saved file data_path.pkl\n"
     ]
    }
   ],
   "source": [
    "from phuc.file import standard_template\n",
    "\n",
    "standard_template.save_data_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Setup Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURR_DIR = os.getcwd().split('/src')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file data_path.pkl\n"
     ]
    }
   ],
   "source": [
    "data_path = file.load_pickle(CURR_DIR + '/data_path.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_DIR\n",
      "OUTPUTS\n",
      "TRAIN_CSV_PKL_PATH\n",
      "TEST_CSV_PKL_PATH\n",
      "METADATA_PKL_PATH\n",
      "WORKING_DIR\n",
      "SAMPLE_SUBMISSION_CSV_PATH\n",
      "TEST_CSV_PATH\n",
      "TRAIN_CSV_PATH\n",
      "EXTERNAL_DIR\n"
     ]
    }
   ],
   "source": [
    "for key in data_path: print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Original author CPMP : https://www.kaggle.com/cpmpml\n",
    "    In kernel : https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "\n",
    "def target_encode(trn_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[\n",
    "        target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / \\\n",
    "        (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * \\\n",
    "        (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(\n",
    "            columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(\n",
    "            columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file train_csv.pkl\n",
      "Loaded file test_csv.pkl\n"
     ]
    }
   ],
   "source": [
    "train_csv = file.load_pickle(data_path['TRAIN_CSV_PKL_PATH'])\n",
    "test_csv = file.load_pickle(data_path['TEST_CSV_PKL_PATH'])\n",
    "\n",
    "target = train_csv['target']\n",
    "del train_csv['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = [\n",
    "    \"ps_car_13\",  # : 1571.65 / shadow  609.23\n",
    "    \"ps_reg_03\",  # : 1408.42 / shadow  511.15\n",
    "    \"ps_ind_05_cat\",  # : 1387.87 / shadow   84.72\n",
    "    \"ps_ind_03\",  # : 1219.47 / shadow  230.55\n",
    "    \"ps_ind_15\",  # :  922.18 / shadow  242.00\n",
    "    \"ps_reg_02\",  # :  920.65 / shadow  267.50\n",
    "    \"ps_car_14\",  # :  798.48 / shadow  549.58\n",
    "    \"ps_car_12\",  # :  731.93 / shadow  293.62\n",
    "    \"ps_car_01_cat\",  # :  698.07 / shadow  178.72\n",
    "    \"ps_car_07_cat\",  # :  694.53 / shadow   36.35\n",
    "    \"ps_ind_17_bin\",  # :  620.77 / shadow   23.15\n",
    "    \"ps_car_03_cat\",  # :  611.73 / shadow   50.67\n",
    "    \"ps_reg_01\",  # :  598.60 / shadow  178.57\n",
    "    \"ps_car_15\",  # :  593.35 / shadow  226.43\n",
    "    \"ps_ind_01\",  # :  547.32 / shadow  154.58\n",
    "    \"ps_ind_16_bin\",  # :  475.37 / shadow   34.17\n",
    "    \"ps_ind_07_bin\",  # :  435.28 / shadow   28.92\n",
    "    \"ps_car_06_cat\",  # :  398.02 / shadow  212.43\n",
    "    \"ps_car_04_cat\",  # :  376.87 / shadow   76.98\n",
    "    \"ps_ind_06_bin\",  # :  370.97 / shadow   36.13\n",
    "    \"ps_car_09_cat\",  # :  214.12 / shadow   81.38\n",
    "    \"ps_car_02_cat\",  # :  203.03 / shadow   26.67\n",
    "    \"ps_ind_02_cat\",  # :  189.47 / shadow   65.68\n",
    "    \"ps_car_11\",  # :  173.28 / shadow   76.45\n",
    "    \"ps_car_05_cat\",  # :  172.75 / shadow   62.92\n",
    "    \"ps_calc_09\",  # :  169.13 / shadow  129.72\n",
    "    \"ps_calc_05\",  # :  148.83 / shadow  120.68\n",
    "    \"ps_ind_08_bin\",  # :  140.73 / shadow   27.63\n",
    "    \"ps_car_08_cat\",  # :  120.87 / shadow   28.82\n",
    "    \"ps_ind_09_bin\",  # :  113.92 / shadow   27.05\n",
    "    \"ps_ind_04_cat\",  # :  107.27 / shadow   37.43\n",
    "    \"ps_ind_18_bin\",  # :   77.42 / shadow   25.97\n",
    "    \"ps_ind_12_bin\",  # :   39.67 / shadow   15.52\n",
    "    \"ps_ind_14\",  # :   37.37 / shadow   16.65\n",
    "    \"ps_car_11_cat\"  # Very nice spot from Tilii : https://www.kaggle.com/tilii7\n",
    "]\n",
    "\n",
    "# add combinations\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),\n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.1"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for ix, (feature_1, feature_2) in enumerate(combs):\n",
    "    # comb_feature name\n",
    "    comb_feature = feature_1 + \"_plus_\" + feature_2\n",
    "    # Print Time Process\n",
    "    print('current feature %60s %4d in %5.1f'\n",
    "          % (comb_feature, ix + 1, (time.time() - start) / 60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "\n",
    "    # create comb_feature in train and test set\n",
    "    train_csv[comb_feature] = train_csv[feature_1].apply(lambda x: str(\n",
    "        x)) + \"_\" + train_csv[feature_2].apply(lambda x: str(x))\n",
    "\n",
    "    test_csv[comb_feature] = test_csv[feature_1].apply(lambda x: str(\n",
    "        x)) + \"_\" + test_csv[feature_2].apply(lambda x: str(x))\n",
    "\n",
    "    # Label Encode\n",
    "    le = LabelEncoder()\n",
    "    # fit\n",
    "    le.fit(list(train_csv[comb_feature].values) +\n",
    "           list(test_csv[comb_feature].values))\n",
    "    # transform\n",
    "    train_csv[comb_feature] = le.transform(list(train_csv[comb_feature].values))\n",
    "    test_csv[comb_feature] = le.transform(list(test_csv[comb_feature].values))\n",
    "    \n",
    "    train_features.append(comb_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = train_csv[train_features]\n",
    "test_csv = test_csv[train_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [column for column in train_csv.columns if \"_cat\" in column]\n",
    "for column in cat_columns:\n",
    "    train_csv[column + \"_avg\"], \\\n",
    "        test_csv[column + \"_avg\"] = target_encode(trn_series=train_csv[column],\n",
    "                                                  tst_series=test_csv[column],\n",
    "                                                  target=target,\n",
    "                                                  min_samples_leaf=200,\n",
    "                                                  smoothing=10,\n",
    "                                                  noise_level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "n_estimators = 200\n",
    "np.random.seed(0)\n",
    "increase = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=15) \n",
    "imp_df = np.zeros((len(train_csv.columns), n_splits))\n",
    "xgb_evals = np.zeros((n_estimators, n_splits))\n",
    "oof = np.empty(len(test_csv))\n",
    "predictions = np.zeros(len(test_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-88-0a91aada45e7>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"eval_gini\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at <ipython-input-88-0a91aada45e7> (7)\n",
      "\n",
      "File \"<ipython-input-88-0a91aada45e7>\", line 7:\n",
      "def eval_gini(y_true, y_prob):\n",
      "    <source elided>\n",
      "    \"\"\"\n",
      "    y_true = np.asarray(y_true)\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "<ipython-input-88-0a91aada45e7>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"eval_gini\" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-88-0a91aada45e7>\", line 13:\n",
      "def eval_gini(y_true, y_prob):\n",
      "    <source elided>\n",
      "    n = len(y_true)\n",
      "    for i in range(n-1, -1, -1):\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/phuc/Desktop/Work/Env/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"eval_gini\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-88-0a91aada45e7>\", line 7:\n",
      "def eval_gini(y_true, y_prob):\n",
      "    <source elided>\n",
      "    \"\"\"\n",
      "    y_true = np.asarray(y_true)\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/phuc/Desktop/Work/Env/lib/python3.6/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-88-0a91aada45e7>\", line 7:\n",
      "def eval_gini(y_true, y_prob):\n",
      "    <source elided>\n",
      "    \"\"\"\n",
      "    y_true = np.asarray(y_true)\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 : 0.024455 @ 200 / best score is 0.041039 @   4\n",
      "Fold  2 : 0.100083 @ 200 / best score is 0.112094 @  13\n",
      "Fold  3 : 0.005135 @ 200 / best score is 0.012675 @  24\n"
     ]
    }
   ],
   "source": [
    "for fold_, (train_idx, val_idx) in enumerate(skf.split(target, target)):\n",
    "    train_data, train_tg = train_csv.iloc[train_idx], target.iloc[train_idx]\n",
    "    val_data, val_tg = train_csv.iloc[val_idx], target.iloc[val_idx]\n",
    "\n",
    "    clf = XGBClassifier(n_estimators=n_estimators,\n",
    "                        max_depth=4,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=.1, \n",
    "                        subsample=.8, \n",
    "                        colsample_bytree=.8,\n",
    "                        gamma=1,\n",
    "                        reg_alpha=0,\n",
    "                        reg_lambda=1,\n",
    "                        nthread=2)\n",
    "    # Upsample during cross validation to avoid having the same samples\n",
    "    # in both train and validation sets\n",
    "    # Validation set is not up-sampled to monitor overfitting\n",
    "    if increase:\n",
    "        # Get positive examples\n",
    "        pos = pd.Series(train_tg == 1)\n",
    "        # Add positive examples\n",
    "        train_data = pd.concat([train_data, train_data.loc[pos]], axis=0)\n",
    "        train_tg = pd.concat([train_tg, train_tg.loc[pos]], axis=0)\n",
    "        # Shuffle data\n",
    "        idx = np.arange(len(train_data))\n",
    "        np.random.shuffle(idx)\n",
    "        train_data = train_data.iloc[idx]\n",
    "        train_data = train_data.iloc[idx]\n",
    "        \n",
    "    clf.fit(train_data, train_tg, \n",
    "            eval_set=[(train_data, train_tg), (val_data, val_tg)],\n",
    "            eval_metric=gini_xgb,\n",
    "            early_stopping_rounds=None,\n",
    "            verbose=False)\n",
    "            \n",
    "    # Keep feature importances\n",
    "    imp_df[:, fold_] = clf.feature_importances_\n",
    "\n",
    "    # Find best round for validation set\n",
    "    xgb_evals[:, fold_] = clf.evals_result_[\"validation_1\"][\"gini\"]\n",
    "    # Xgboost provides best round starting from 0 so it has to be incremented\n",
    "    best_round = np.argsort(xgb_evals[:, fold_])[::-1][0]\n",
    "\n",
    "    # Predict OOF and submission probas with the best round\n",
    "    oof[val_idx] = clf.predict_proba(val_data, ntree_limit=best_round)[:, 1]\n",
    "    # Update submission\n",
    "    predictions += clf.predict_proba(test_csv, ntree_limit=best_round)[:, 1] / n_splits\n",
    "\n",
    "    # Display results\n",
    "    print(\"Fold %2d : %.6f @%4d / best score is %.6f @%4d\"\n",
    "          % (fold_ + 1,\n",
    "             eval_gini(val_tg, oof[val_idx]),\n",
    "             n_estimators,\n",
    "             xgb_evals[best_round, fold_],\n",
    "             best_round))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Full OOF score : %.6f\" % eval_gini(\n",
    "    target, oof))  # Compute mean score and std\n",
    "mean_eval = np.mean(xgb_evals, axis=1)\n",
    "std_eval = np.std(xgb_evals, axis=1)\n",
    "best_round = np.argsort(mean_eval)[::-1][0]\n",
    "\n",
    "print(\"Best mean score : %.6f + %.6f @%4d\"\n",
    "      % (mean_eval[best_round], std_eval[best_round], best_round))\n",
    "\n",
    "importances = sorted([(train_csv.columns[i], imp) for i, imp in enumerate(imp_df.mean(axis=1))],\n",
    "                     key=lambda x: x[1])\n",
    "\n",
    "for column, imp in importances[::-1]:\n",
    "    print(\"%-34s : %10.4f\" % (column, imp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv[\"target\"] = predictions\n",
    "\n",
    "test_csv[[\"target\"]].to_csv(data_path['OUTPUTS']+\"/submission.csv\", index=True, float_format=\"%.9f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "411.533px",
    "left": "38px",
    "top": "74.7667px",
    "width": "243.2px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
